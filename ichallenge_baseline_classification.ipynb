{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "# import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "# import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.vision.models import resnet50, resnet101\n",
    "\n",
    "from torchvision import transforms as trans # fro torchvision\n",
    "import albumentations as trans # for albumentations\n",
    "import PIL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def numpy_to_pil(array):\n",
    "    return Image.fromarray(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nums: 400, train: 320, val: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (_thread_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/paddle/io/dataloader/dataloader_iter.py\", line 603, in _thread_loop\n",
      "    batch = self._get_data()\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/paddle/io/dataloader/dataloader_iter.py\", line 751, in _get_data\n",
      "    batch.reraise()\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/paddle/io/dataloader/worker.py\", line 187, in reraise\n",
      "    raise self.exc_type(msg)\n",
      "TypeError: DataLoader worker(1) caught TypeError with message:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/paddle/io/dataloader/worker.py\", line 372, in _worker_loop\n",
      "    batch = fetcher.fetch(indices)\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/paddle/io/dataloader/fetcher.py\", line 85, in fetch\n",
      "    data = self.collate_fn(data)\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/paddle/io/dataloader/collate.py\", line 75, in default_collate_fn\n",
      "    return [default_collate_fn(fields) for fields in zip(*batch)]\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/paddle/io/dataloader/collate.py\", line 75, in <listcomp>\n",
      "    return [default_collate_fn(fields) for fields in zip(*batch)]\n",
      "  File \"/home/nate/.local/lib/python3.10/site-packages/paddle/io/dataloader/collate.py\", line 77, in default_collate_fn\n",
      "    raise TypeError(\n",
      "TypeError: batch data con only contains: tensor, numpy.ndarray, dict, list, number, but got <class 'PIL.Image.Image'>\n",
      "\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "(Fatal) Blocking queue is killed because the data reader raises an exception.\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:175)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 227\u001b[0m\n\u001b[1;32m    224\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mAdam(init_lr, parameters\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m    226\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m--> 227\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# 预测阶段\u001b[39;00m\n\u001b[1;32m    232\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./classification/best_model_0.9875/model.pdparams\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 115\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iters, train_dataloader, val_dataloader, optimizer, criterion, log_interval, eval_interval)\u001b[0m\n\u001b[1;32m    113\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m<\u001b[39m iters:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m>\u001b[39m iters:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/paddle/io/dataloader/dataloader_iter.py:825\u001b[0m, in \u001b[0;36m_DataLoaderIterMultiProcess.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_queue\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_dynamic_mode():\n\u001b[1;32m    824\u001b[0m     data \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39meager\u001b[38;5;241m.\u001b[39mread_next_tensor_list(\n\u001b[0;32m--> 825\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_next_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    826\u001b[0m     )\n\u001b[1;32m    827\u001b[0m     data \u001b[38;5;241m=\u001b[39m _restore_batch(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure_infos\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mSystemError\u001b[0m: (Fatal) Blocking queue is killed because the data reader raises an exception.\n  [Hint: Expected killed_ != true, but received killed_:1 == true:1.] (at /paddle/paddle/fluid/operators/reader/blocking_queue.h:175)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as trans\n",
    "\n",
    "batchsize = 8 \n",
    "image_size = 256\n",
    "iters = 1000 \n",
    "val_ratio = 0.2 # 80 / 20\n",
    "trainset_root = \"../data-PALM/Training/Images\"\n",
    "val_root = \"../data-PALM/Training/Images\"\n",
    "num_workers = 4\n",
    "init_lr = 1e-6\n",
    "optimizer_type = \"adam\"\n",
    "\n",
    "\n",
    "filelists = os.listdir(trainset_root)\n",
    "train_filelists, val_filelists = train_test_split(filelists, test_size=val_ratio, random_state=42)\n",
    "print(\"Total Nums: {}, train: {}, val: {}\".format(len(filelists), len(train_filelists), len(val_filelists)))\n",
    "\n",
    "\n",
    "class GOALS_sub2_dataset(paddle.io.Dataset):\n",
    "    def __init__(self,\n",
    "                img_transforms,\n",
    "                dataset_root,\n",
    "                label_file='',\n",
    "                filelists=None,\n",
    "                numclasses=2,\n",
    "                mode='train'):\n",
    "        self.dataset_root = dataset_root\n",
    "        self.img_transforms = img_transforms\n",
    "        self.mode = mode.lower()\n",
    "        self.num_classes = numclasses\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            label = {row['imgName']:row[1]\n",
    "                    for _, row in pd.read_excel(label_file).iterrows()}            \n",
    "            self.file_list = [[f, label[f]] for f in os.listdir(dataset_root)]\n",
    "\n",
    "\n",
    "        elif self.mode == \"test\":\n",
    "            self.file_list = [[f, None] for f in os.listdir(dataset_root)]\n",
    "        \n",
    "        if filelists is not None:\n",
    "            self.file_list = [item for item in self.file_list if item[0] in filelists]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        real_index, label = self.file_list[idx]\n",
    "        img_path = os.path.join(self.dataset_root, real_index)    \n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Conversion: If img is a NumPy array, convert to PIL Image\n",
    "        if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.img_transforms is not None:\n",
    "            img = self.img_transforms(img)\n",
    "\n",
    "        # Convert PIL Image to Tensor\n",
    "        img = transforms.ToTensor()(img) \n",
    "            \n",
    "        if self.__getitem__ is not None:\n",
    "            img = self.img_transforms(img)\n",
    "            #print(\"Image transformed:\", img)  # Add this line\n",
    "\n",
    "        \n",
    "        \n",
    " \n",
    "        # normlize on GPU to save CPU Memory and IO consuming.\n",
    "        # img = (img / 255.).astype(\"float32\")\n",
    "\n",
    "        img = img.transpose(PIL.Image.TRANSPOSE) # H, W, C -> C, H, W\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return img, real_index\n",
    "\n",
    "        if self.mode == \"train\":            \n",
    "            return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "\n",
    "img_train_transforms = trans.Compose([\n",
    "    trans.RandomResizedCrop(\n",
    "        image_size, scale=(0.90, 1.1), ratio=(0.90, 1.1)),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(30)\n",
    "])\n",
    "\n",
    "img_val_transforms = trans.Compose([\n",
    "    trans.CenterCrop(image_size),\n",
    "    trans.Resize((image_size, image_size))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.feature = resnet50(pretrained=True, num_classes=2) # 移除最后一层全连接\n",
    "        # self.feature = resnet101(pretrained=True, num_classes=2) # 移除最后一层全连接\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2)\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self. feature(img)\n",
    "        out1 = self.fc1(feature)\n",
    "        logit = self.fc2(out1)\n",
    "\n",
    "        return logit\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iters, train_dataloader, val_dataloader, optimizer, criterion, log_interval, eval_interval):\n",
    "    iter = 0\n",
    "    model.train()\n",
    "    avg_loss_list = []\n",
    "    avg_acc_list = []\n",
    "    best_acc = 0.\n",
    "    while iter < iters:\n",
    "        for data in train_dataloader:\n",
    "            iter += 1\n",
    "            if iter > iters:\n",
    "                break\n",
    "            imgs = (data[0] / 255.).astype(\"float32\")\n",
    "            labels = data[1].astype('int64')\n",
    "            # print(labels)\n",
    "            labels_ = paddle.unsqueeze(labels, axis=1)\n",
    "            logits = model(imgs) \n",
    "            m = paddle.nn.Softmax()\n",
    "            pred = m(logits)\n",
    "            # print(pred.numpy())\n",
    "            # print(pred.numpy().argmax(1))            \n",
    "            acc = paddle.metric.accuracy(input=pred, label=labels_)\n",
    "            one_hot_labels = paddle.fluid.layers.one_hot(labels_, 2, allow_out_of_range=False)\n",
    "            loss = criterion(pred, one_hot_labels)            \n",
    "            # print(loss.numpy())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.clear_gradients()\n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "            avg_acc_list.append(acc.numpy())\n",
    "            \n",
    "\n",
    "            if iter % log_interval == 0:\n",
    "                avg_loss = np.array(avg_loss_list).mean()\n",
    "                avg_acc = np.array(avg_acc_list).mean()\n",
    "                avg_loss_list = []\n",
    "                avg_acc_list = []\n",
    "                print(\"[TRAIN] iter={}/{} avg_loss={:.4f} avg_acc={:.4f}\".format(iter, iters, avg_loss, avg_acc))\n",
    "\n",
    "            if iter % eval_interval == 0:\n",
    "                avg_loss, avg_acc = val(model, val_dataloader, criterion)\n",
    "                print(\"[EVAL] iter={}/{} avg_loss={:.4f} acc={:.4f}\".format(iter, iters, avg_loss, avg_acc))\n",
    "                if avg_acc >= best_acc:\n",
    "                    best_acc = avg_acc\n",
    "                    paddle.save(model.state_dict(),\n",
    "                            os.path.join(\".../classification/best_model_{:.4f}\".format(best_acc), 'model.pdparams'))\n",
    "                model.train()\n",
    "\n",
    "def val(model, val_dataloader, criterion):\n",
    "    model.eval()\n",
    "    avg_loss_list = []\n",
    "    avg_acc_list = []\n",
    "    cache = []\n",
    "    with paddle.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            imgs = (data[0] / 255.).astype(\"float32\")\n",
    "            labels = data[1].astype('int64')\n",
    "            labels_ = paddle.unsqueeze(labels, axis=1)\n",
    "            logits = model(imgs)\n",
    "            m = paddle.nn.Softmax()\n",
    "            pred = m(logits)            \n",
    "            acc = paddle.metric.accuracy(input=pred, label=labels_)\n",
    "            one_hot_labels = paddle.fluid.layers.one_hot(labels_, 2, allow_out_of_range=False)\n",
    "            loss = criterion(pred, one_hot_labels) \n",
    "            avg_loss_list.append(loss.numpy()[0])\n",
    "            avg_acc_list.append(acc.numpy())        \n",
    "\n",
    "    avg_loss = np.array(avg_loss_list).mean()\n",
    "    acc = np.array(avg_acc_list).mean()\n",
    "\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "img_train_transforms = trans.Compose([\n",
    "    trans.RandomResizedCrop(\n",
    "        image_size, scale=(0.90, 1.1), ratio=(0.90, 1.1)),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "    trans.RandomVerticalFlip(),\n",
    "    trans.RandomRotation(30)\n",
    "])\n",
    "\n",
    "\n",
    "img_val_transforms = trans.Compose([\n",
    "    trans.CenterCrop(image_size),\n",
    "    trans.Resize((image_size, image_size))\n",
    "])\n",
    "\n",
    "train_dataset = GOALS_sub2_dataset(dataset_root=trainset_root, \n",
    "                        img_transforms=img_train_transforms,\n",
    "                        filelists=train_filelists,\n",
    "                        label_file='../data-PALM/Training/Classification Labels.xlsx')\n",
    "\n",
    "val_dataset = GOALS_sub2_dataset(dataset_root=trainset_root, \n",
    "                        img_transforms=img_val_transforms,\n",
    "                        filelists=val_filelists,\n",
    "                        label_file='../data-PALM/Training/Classification Labels.xlsx')\n",
    "\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(train_dataset, batch_size=batchsize, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "val_loader = paddle.io.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_sampler=paddle.io.DistributedBatchSampler(val_dataset, batch_size=batchsize, shuffle=True, drop_last=False),\n",
    "    num_workers=num_workers,\n",
    "    return_list=True,\n",
    "    use_shared_memory=False\n",
    ")\n",
    "\n",
    "model = Model()\n",
    "\n",
    "if optimizer_type == \"adam\":\n",
    "    optimizer = paddle.optimizer.Adam(init_lr, parameters=model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train(model, iters, train_loader, val_loader, optimizer, criterion, log_interval=10, eval_interval=100)\n",
    "\n",
    "\n",
    "\n",
    "# 预测阶段\n",
    "best_model_path = './classification/best_model_0.9875/model.pdparams'\n",
    "model = Model()\n",
    "para_state_dict = paddle.load(best_model_path)\n",
    "model.set_state_dict(para_state_dict)\n",
    "model.eval()\n",
    "\n",
    "test_root = \"../data-PALM/Validation/Images\"\n",
    "img_test_transforms = trans.Compose([\n",
    "    trans.CropCenterSquare(),\n",
    "    trans.Resize((image_size, image_size))\n",
    "])\n",
    "\n",
    "test_dataset = GOALS_sub2_dataset(dataset_root=test_root, \n",
    "                        img_transforms=img_test_transforms,\n",
    "                        mode='test')\n",
    "cache = []\n",
    "for img, idx in test_dataset:\n",
    "    img = img[np.newaxis, ...]\n",
    "    img = paddle.to_tensor((img / 255.).astype(\"float32\"))\n",
    "    logits = model(img) \n",
    "    m = paddle.nn.Softmax()\n",
    "    pred = m(logits)\n",
    "    print(pred.numpy())\n",
    "    cache.append([idx, pred.numpy()[0][1]])\n",
    "\n",
    "submission_result = pd.DataFrame(cache, columns=['imgName', 'GC_Pred'])\n",
    "submission_result[['imgName', 'GC_Pred']].to_csv(\"./results/submission_val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
